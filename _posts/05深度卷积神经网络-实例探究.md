---
title: 05深度卷积神经网络-实例探究
categories: [计算机视觉,吴恩达深度学习]
tags: [深度学习]
mathjax: true
toc: true
---

### 经典的卷积网络模型

　　介绍几种经典的卷积神经网络结构，分别是<span class="blockFont">LeNet</span> 、<span class="blockFont">AlexNet</span>  、<span class="blockFont">VGGNet</span> 。

#### LeNet-5

<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/01.png" style="zoom:67%;" />

<!--more-->

　　`LeNet-5` 提出的时间比较早，最早在[LeCun et al. 1998. Gradient-based learning applied to document recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)  这篇paper中被提出，它主要是针对灰度图设计的，所以其输入较小。相比于现代网络模型版本，这里得到的神经网络会小一些，只有约6万个参数。
　　在`LeNet-5` 中存在的一种经典的模式：
　　$$conv\ \rightarrow \  pool \ \rightarrow \ conv \rightarrow \ pool \rightarrow \ fc \ \rightarrow \ fc \ \rightarrow \ ouput$$ 
　　**注意：** 在`LeNet-5` 随着网络的深度加深，图像的大小在缩小，但与此同时，通道(即图像深度)的数量却在增加。

#### AlexNet

<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/02.png" style="zoom:67%;" />

　　`AlexNet` 直接对彩色的大图片进行处理，其最早提出是在[Krizhevsky et al. 2012. ImageNet classificatin with deep convolutional neural networks](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf) 这篇paper中。
　　实际上，`Alexnet` 与`LeNet` 有很多相似之处，不过从上图中我们可以看出， AlexNet 比LeNet要大得多，正如前面讲到的LeNet大约有6万个参数，而AlexNet 包含约6000万个参数！
　　当用于训练图像和数据集时，AlexNet能够处理非常相似的基本构造模块，这些模块往往包含了大量的隐藏单元或数据，这一点令AlexNet 表项出色，AlexNet 比LeNet表现更出色的还有一个原因就是，它使用了`ReLU激活函数` ，在LeNet中使用的是`Sigmod激活函数` 和`Tanh函数` 。AlexNet使得深度学习在计算机视觉方面受到了极大的重视。

#### VGG-16

<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/03.png" style="zoom:67%;" />

　　`VGG网络` 的一大优点，就是它的确简化了神经网络结构，而且值得注意的一点是`VGG-16` 没有那么多超参数，这是一种只需要专注于构建卷积层的简单神经网络，其最早在[Simonvan & Zisserman  2015. Very deep convolutional networks for large-scale image recognition](https://arxiv.org/pdf/1409.1556.pdf) 这篇paper中提出。
　　顺便说一下，`VGG-16` 中的16，就是指网络中包含了16个卷积层和全连接层。总体来说，VGG-16确实是个很大的网络，其总共包含了约1.38亿个参数，但是VGG-16的结构并不复杂，这一点非常吸引人，而且这种网络结构很规整，都是几个卷积层后面跟着可以压缩图像大小的池化层，同时卷积层的过滤器数量变化存在一定的规律。
　　VGG-16的主要缺点：需要训练的特征数量非常巨大。

### 残差网络(ResNets)

　　在一般的神经网络中，随着层数的加深，当层数深到一定程度的时候，梯度下降的情况并不会像理论上那样一直处于下降的状态，而是会极大可能出现`梯度消失的现象`。为解决这个问题，使得我们可以训练很深的神经网络，[He et al. 2015. Deep residual network for image recognition](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf) 这篇paper提出了残差网络(ResNets)。

#### 残差块(Residual block)

<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/04.png" style="zoom:67%;" />

　　构建一个ResNets网络的过程，其实就是将`残差块` 连接在一起，从而构成一个深度神经网络。残差块的构成如上图中所示，其数学描述如下：

$$a^{[l]} \rightarrow Liner \ \rightarrow \  ReLU \ \rightarrow \  Liner \ \rightarrow \  ReLU \ \rightarrow \  a^{[l+2]}=g(z^{l+2}+a^{[l]})$$ 

　　 残差块与一般的网络不一样的地方，就在于最后一项 $a^{[l+2]}=g(z^{l+2}+a^{[l]})$ ，在对$z^{[l+2]}$ 进行非线性激活之前，对其加上了$a^{[l]}$ 这一项，这个操作被称为`跳跃连接` 或者`short cut\skip connection` ，以上就是对残差块的数学描述。

#### 构建残差网络(Residual Network) 

<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/05.png" style="zoom:67%;" />

　　对于一个普通网络而言，其深度越深，也就意味着用优化算法越难训练，而且，实际上，随着网络的加深，训练错误也会越来越多。如上图所示，我们可以知道，在网络越来越深的情况下，网络连接会变得臃肿，但是ResNets确实在训练深度网络方面非常有效，可以解决梯度消失和梯度爆炸的问题。

#### 为什么残差网络能够工作的很好？

<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/06.png" style="zoom:67%;" />

　　对于残差块的最后一项 $a^{[l+2]}=g(z^{[l+2]}+a^{[l]})$ ，如果输入$a^{[l]}$ 和输出$a^{[l+2]}$ 的维度不同，则我们需要通过给$a^{[l]}$ 加上一个系数矩阵$W_s$ ，$W_s$ 是通过网络学习得到的矩阵或参数，它是一个固定的矩阵，并且其padding=0。
　　所以残差块的最后一项的最终表达为：

$$a^{[l+2]}=g(z^{[l+2]}+W_s\ast a^{[l]})=g(W^{[l+2]}\ast a^{[l+1]}+b^{[l+1]}+W_s\ast a^{[l]})$$ 

　　当$W^{[l+1]}=0,b^{[l+1]}=0$ 时，即梯度消失的时候，其结果为：

$$a^{[l+2]}=g(a^{[l]})=a^{[l]}$$ 

　　**注意：** 上述公式中的函数 $g$ 是$ReLU$ 激活函数。

　　残差网络起作用的主要原因，就是这些残差块学习上述的恒等函数非常容易，可以确定网络性能不会受到影响，很多时候甚至可以提高效率，或者说至少不会降低网络效率，因此创建类似残差网络可以提升网络性能。
　　除此之外，关于残差网络，另一个值得探讨的细节是：假设$z^{[l+2]}$ 与 $a^{[l]}$ 具有相同的维度，即ResNets使用了许多相同的卷积，所以$a^{[l]}$ 的维度等于这个输出层的维度，因而实现了这个跳远连接，因为同一个卷积保留了维度，所以很容易得出这个短连接，并输出相同维度的向量。

#### ResNets结构

<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/07.png" style="zoom:67%;" />

　　整个ResNets网络中，主要有两个模块构成，一个是重复叠加的相同的`相同块` ，还有一个就是用于调整$W_s$ 的`卷积块` 

##### The identity block

<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/08.png" style="zoom:67%;" />

　　在上图中，弧线表示的是跳跃连接路线称为`shortcut path` ，下面则称为主路线`main path` ，为了加快网络的训练，在图中还加入了归一化操作`BatchNorm` 。

##### The convolutional block

<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/09.png" style="zoom:67%;" />

　　卷积块是另一种类型的块，不要认为因为只是在`相同块` 的基础上添加了内容，所以本质上还是`相同块`，当输入和输出的维度不匹配的时候，可以使用它来进行调整，和相同块不同的是，卷积块在`shortcut path` 上添加了一个卷积层。

##### example(50 layers)

<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/10.png" style="zoom:67%;" />

　　上图中的`ID BLOCK` 表示的是`相同块` ，`ID BLOCK x3` 表示有3个相同块叠加在一起。

#### 小结

　　ResNets的注意事项：

* 非常深的的普通网络，在实践中它们并不起作用，因为梯度消失使得非常难训练；
* `skip connection` 可以使梯度消失得到很好的解决，它也使得残差块更容易学习；
* ResNets中有主要的两中类型的残差块：相同块和卷积块；
* 将这些残差块连接起来，就可以构建非常深的残差网络了。

### 1x1卷积

#### 1X1卷积运算

<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/11.png" style="zoom:67%;" />

　　在二维上的卷积相当于图片的每个元素和对应的一个卷积核数字相乘，但是在三维上，与$1\times 1\times n_C$ 卷积核进行卷积， 相当于三维图像上的 $1\times 1\times n_C$ 的切片，也就是 $n_c$ 个元素乘以卷积数值权重，通过$ReLU$ 函数后输出对应的结果，而不同的卷积核则相当于不同的隐藏层神经元结点与切片上的元素进行一一连接。
　　所以，根本上$1\times 1$ 卷积核相当于对一个切片上的 $n_C$ 个单元 都应用了一个全连接的神经网络。最终三维的图像应用$1\times 1$ 的卷积核得到一个相同长宽，但第三维度变为了卷积核个数的图像。

#### 使用1x1卷积

<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/12.png" style="zoom:67%;" />

　　对于输入图像的高度和宽度，我们可以使用池化层来压缩，但对于其深度(信道数量$n_C$)，我们则可以使用$1\times 1$ 卷积来进行压缩，如上图所示，对于一个$28\times 28 \times 192 $ 的图像数据，我们可以使用32个$1\times 1 \times 192$ 的卷积核对其进行卷积操作，最后得到一个$28\times 28\times 32$ 的输出。这一点，将会在接下来要介绍的`Inception Network` 使用到。
　　**注意：** 卷积核的第三维也就是信道数必须要和输入层中的信道数量保持一致。

### Inception Network(gooLeNet)

#### Inception Network主要结构

<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/13.png" style="zoom:67%;" />

　　`Inception 网络` 的作用，就是要代替人工来确定卷积层中的过滤器类型，或者确定是否需要创建卷积层或池化层，该网络结构在[Szegedy et al. 2014. Going deeper with convolutions](https://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf) 这篇paper中被首先提出。
　　在上面的Inception结构中，应用了不同的卷积核，以及带padding的池化层。在保持输入图片大小不变的情况下，通过不同运算结果的叠加，增加了通道的数量。卷积核分别用了64 个$1\times 1 \times 192$ 的卷积核、128个$3\times 3 \times 192$ 的卷积核、32个$5\times 5 \times 192$ 的卷积核以及32个$MAX-POOL$ 。
　　需要注意的是这里对$MAX-POOL$ 使用了`same padding` ，以使得该输出和其他经过卷积核运算后的输出的维度一致，从而可以将它与其它层输出连接起来。还有一点就是其他所有卷积核运算都采用了`same padding` ，这样可以保证所有运算的输出结果维度都相同，最后所有输出连接在一起构成了一个$28\times 28\times 256$ 的图像数据。
　　整个网络的基本思想就是，Inception网络不需要人为地决定使用哪个过滤器，或是否需要池化，而是由网络自行确定这些参数，可以给网络添加这些参数的可能值，然后把这些输出连接起来，让网络自己学习它需要什么样的参数，采用哪些过滤器组合。

#### Inception Network存在的问题

　　对于Inception Network，其最大的问题就是`计算成本过大` ：

<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/14.png" style="zoom:67%;" />

　　对32个$5\times 5 \times 192$ 的卷积核，其在网络中的乘法计算量为：

$$(28\times 28 \times 32)  \times  (5\times 5 \times 192)=120M$$
　　即整个计算过程中，需要计算$28\times 28 \times 32$ 个数值，而且对于输出中的每个数值来说，都需要执行 $5\times 5\times 192$ 次乘法运算，所以最后乘法运算的总次数为1.2亿次！这个计算代价已经非常巨大了。

#### 使用1x1卷积来解决计算成本过大问题

<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/15.png" style="zoom:67%;" />

　　通过前面介绍的 $1\times 1$ 卷积内容，我们可以知道，$1\times 1$ 卷积核可以对图像深度起到一个压缩的作用，这里正好可以通过这一特性来降低Inception网络的计算成本，其方法就是在进行Inception网络中的卷积操作之前，添加一个 $1\times 1$ 卷积操作。
　　其具体流程为：较大的输入层　　   $\Rightarrow$ 　　$1\times 1$ 卷积　　$\Rightarrow$ 　　$5\times 5$ 卷积　　$\Rightarrow$ 　　输出
　　再对$5\times 5$ 卷积核乘法次数做一个计算：
　　$1\times 1$ 卷积：$(28\times 28 \times 16) \times (1\times 1 \times 192)=2.4M$ 
　　$5\times 5$ 卷积：$(28\times 28\times 32)\times (5\times 5 \times 16)=10.0M$ 
　　总的乘法次数：$2.4M+10.0M=12.4M$ ，我们发现乘法次数仅为1240万次，是原来1.2亿的十分之一！

#### Inception网络模块

<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/16.png" style="zoom:67%;" />

　　Inception网络最终的组成模块，如上图所示，在三个卷积核之前都各自添加了一个$1\times 1$ 的卷积操作，这个原因已经在前面说明。不过需要注意的一点是对$MAX-POOL$ 的处理，如果进行了最大池化，即便使用了same padding，其输出将会是$28\times 28 \times 192$ ，通道数量或者说深度，与输入相同，所以看起来它会有很多通道，实际上还需要做的就是在后面再加一个$1\times 1$ 的卷积层，将其通道数进行压缩，最后和其他输出连接在一起。

#### Inception网络组成

<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/17.png" style="zoom:67%;" />

　　上图中的Inception网络中，除了重复的模块(前一小节提到的)，还有一个细节就是，网络中其实还有一些分支，这些分支确保了，即便是隐藏层和中间层，也参与了特征计算，它们也能预测图像的分类，这在网络中可以起到一种调整的效果，并且能防止网络发生过拟合。

### 迁移学习

　　如果要做一个计算机视觉的应用，相比于从头训练权重，或者说从随机初始化权重开始，去下载别人已经训练好的网络结构的权重，用这个作为训练结果，然后转换到我们感兴趣的任务上，通常能够进展的快很多。因为有时候这些训练需要花费好几周时间，并且需要很多的GPU。
　　这些训练过程是其他人做过了，并且经历了非常痛苦的寻找最优的过程，这就意味着你可以下载，花费了别人好几周甚至几个月，而做出来的开源的权重参数，把它当作一个很好的初始化，用在自己的神经网络上。

#### 迁移学习的方法

<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/18.png" style="zoom:67%;" />

　　在迁移学习中，所有的中间网络层都需要看作是冻结的，即我们不能对其进行修改，对于这些层的参数，我们只需要训练和最后一个softmax层有关的参数，我们能够修改的只有这个最后的输出层，即softmax层，对于该层，我们甚至可以去掉原有的softmax层，而创建自己的softmax层。

#### 相关技巧

　　取输入图像$X$ ，把它映射到最后一层的激活函数(上一节图中的绿色框)，能够加速训练的技巧就是：我们先计算这一层的特征或激活值，然后把它们存到硬盘上。你所要做的就是，用这个固定的函数在这个神经网络的前半部分，取任意输入图像$X$ ，然后计算它的某个特征向量，用这个特征向量来做预测，这样我们训练的就是一个很浅的softmax模型。
　　提前计算训练集中同一样本的这一层的激活值，然后存储到硬盘里，在此之上训练softmax分类器，存储到硬盘，或者说预计算方法的优点，在于我们不需要每次都遍历训练集，再重复计算这个激活值了。

### 数据扩充

　　与其他机器学习问题相比，在计算机视觉领域当下最主要的问题是没有办法得到充足的数据。所以在我们训练计算机数据模型的时候，数据的扩充就是会非常有用。

#### 数据扩种的几种方法

<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/19.png" style="zoom:67%;" />

　　常用的数据扩充的方法有：镜像翻转(Mirroring)和随机剪裁(Random Cropping)。

<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/20.png" style="zoom:67%;" />

　　还有一种方法就是色彩转换：为图片的RGB三个颜色通道进行增减值操作，比如(R:+20,  G:-20, B:+20)，
　　`PCA颜色增强` ： 对图片的主色变化较大，图片的次色变化较小，使总体颜色保持一致。

#### 训练过程中的数据扩充

<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/%E6%B7%B1%E5%BA%A6%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-%E5%AE%9E%E4%BE%8B%E6%8E%A2%E7%A9%B6/21.png" style="zoom:67%;" />

　　为了节省时间，数据扩充的过程和训练过程可以多CPU多线程来并行的实现。就是使用一个线程来加载训练数据并实现扭曲，然后传给其他的线程或者进程，来实现训练，并且可以并行实现。

----------------------

代码文件:  https://pan.baidu.com/s/1rNg8zdHj58ZwSe8IzFvBng 密码：ooy3
参考：https://blog.csdn.net/koala_tree/article/details/78531398