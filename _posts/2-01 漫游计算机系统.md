---
title: 第一章：漫游计算机系统
categories: [读书笔记,深入理解计算机系统]
tags: [CSAPP]
toc: true
---

　　计算机系统是由硬件和系统软件组成的，它们共同工作来运行应用程序，虽然系统的具体实现方式随着时间不断变化，但是系统内在的概念却没有改变。

<!--more-->

### 信息就是位+上下文

　　hello程序的生命周期是从一个源程序（或者说源文件）开始的，即程序员通过编辑器创建并保存的文本文件，文件名是hello.c。源程序实际上就是一个由值0和1组成的位（又称为比特）序列，`8个位被组织成一组，称为字节`。
　　hello.c程序是以字节序列的方式存储在文件中的。`每个字节都有一个整数值（即ASCII值）对应于某些字符`。其表示方法说明了一个基本思想：系统中所有的信息（包括磁盘文件、内存中的程序、内存中存放的用户数据以及网络上传送的数据），都是由一串比特表示的。区分不同数据对象的唯一方法是我们读到这些数据对象的上下文。比如在不同的上下文中，一个同样的字节序列可能表示一个整数、浮点数、字符串或者机器指令。

### 程序被其他程序翻译成不同的格式

　　在Unix系统上，从源文件到目标文件的转化是由编译器驱动程序完成的：

```shell
gcc -o hello hello.c
```

　　在这里，GCC编译器驱动程序读取源程序文件hello.c，并把它翻译成一个可执行目标文件hello。这个翻译过程可分为四个阶段完成，如图1所示，执行这四个阶段的程序（预处理器、编译器、汇编器和链接器）一起构成了编译系统：

　　　　　　　　<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/02%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/01.png" width=80% height=80%>

　　　　　　　　　　　　　　　　　　　　　　　　　　　图1：编译系统

### 了解编译系统如何工作是大有益处的

　　对于像hello.c这样简单的程序，我们可以依靠编译系统生成正确有效的机器代码。但是，有一些重要的原因促使程序员必须知道编译系统是如何工作的：
　　**优化程序性能**：现代编译器都是成熟的工具，通常可以生成很好的代码，作为程序员，我们无须为了写出高效代码而去了解编译器的内部工作。但是，为了在C程序中做出好的编码选择，我们确实需要了解一些机器代码以及编译器将不同的C语句转化为机器代码的方式。比如，`一个switch语句是都总是比一系列的if-else语句高效的多？`一个函数调用的开销有多大？while循环比for循环更有效吗？指针引用比数组索引更有效吗？`为什么将循环求和的结果放到一个本地变量中，会比将其放到一个通过引用传递过来的参数中，运行起来快的多呢？`为什么我们只是简单地重新排列下算术表达式中的括号就能让函数运行得更快？
　　**理解链接时出现的错误：**根据我们的经验，一些最令人困扰的程序错误往往都与链接器操作有关，尤其是当你试图构建大型的软件系统时，比如，链接器报告说它无法解析一个引用，这是什么意思？静态变量和全局变量的区别是什么？如果你在不同C文件中定义了名字相同的两个全局变量会发生什么？静态库和动态库的区别是什么？我们在命令行上排列库的顺序有什么影响？最严重的是，为什么有些链接错误直到运行时才会出现？
　　**避免安全漏洞：**多年来，缓冲区溢出错误是造成大多数网络和Internet服务器上安全漏洞的主要原因。存在这些错误是因为很少程序员能够理解需要限制从不受信任的源接收数据的数量和格式。学习安全编程的第一步就是理解数据和控制信息存储在程序栈上的方式会引起的后果。

### 系统的硬件组成

　　为了理解运行hello程序时，处理器是如何读取并解释在内存中的指令，我们需要了解一个典型系统的硬件组织：
　　**总线：**贯穿整个系统的是一组电子管道，称作总线，它携带信息字节并负责在各个部件间传递。`通常总线被设计成传送定长的字节块，也就是字（word）。字中的字节数（即字长）是一个基本的系统参数，各个系统中都不尽相同`。现在的大多数机器字长要么是4字节（32位），要么是8个字节（64位）。本书中，我们不对字长做任何固定的假设。
　　**I/O设备：**I/O（输入/输出）设备是系统与外部世界的联系通道，每个I/O设备都通过一个控制器或适配器与I/O总线相连，控制器和适配器之间的区别主要在于它们的封装方式。控制器是I/O设备本身或者系统的主印制电路板（通常称作主板）上的芯片组。而适配器则是一块插在主板插槽上的卡。
　　**主存：**主存是一个临时存储设备，在处理器执行程序时，用来存放程序和程序处理的数据。从物理上来说，主存是由一组`动态随机存取存储器（DRAM）芯片`组成的。从逻辑上来说，存储器是一个线性的字节数组，每个字节都有其唯一的地址（数组索引），这些地址是从零开始的。
　　**处理器：**中央处理单元（CPU），简称处理器，是解释（或执行）存储在主存中的指令的引擎。`处理器的核心是一个大小为一个字的存储设备（或寄存器）`，称为程序计数器（PC）。在任何时刻，PC都指向主存中的某条机器语言指令（即含有该条指令的地址）。执行指令的每一条简单操作，都围绕着主存、寄存器文件和算术/逻辑单元（ALU）进行。`寄存器文件是一个小的存储设备，由一些单个字长的寄存器组成，每个寄存器都有唯一的名字`。

　　　　　　　　　　　　　　　<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/02%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/02.png" width=55% height=55%>

　　　　　　　　　　　　　　　　　　　　　图2：一个典系统的硬件组成

### 高速缓存至关重要

　　根据机械原理，较大的存储设备要比较小的存储设备运行得慢，而快速设备的造价远高于同类的低速设备。比如说，`一个典型系统上的磁盘驱动器可能比主存大1000倍，但是对处理器而言，从磁盘驱动器读取一个字的时间开销要比从主存中读取的开销大1000万倍`。类似地，`一个典型的寄存器文件只存储几百字节的信息，而主存里可存放几十亿字节。然而，处理器从寄存器文件中读数据比主存中读取几乎要快100倍`。更麻烦的是，随着这些年半导体技术的进步，这种处理器与主存之间的差距还在持续增大。加快处理器的运行速度比加快主存的运行速度要容易和便宜得多。
　　针对这种处理器与主存之间的差异，系统设计者采用了更小更快的存储设备，称为高速缓存存储器（简称cache或高速缓存），作为暂时的集结区域，存放处理器近期可能会需要的信息。`位于处理器芯片上的L1高速缓存的容量可以达到数万字节，访问速度几乎和寄存器一样快`。一个容量为数十万到数百万字节的更大的L2高速缓存通过一条特殊的总线连接到处理器。进程访问L2高速缓存的时间要比访问L1高速缓存的时间长5倍，但是这仍然比访问主存的时间快5至10倍。
　　`L1和L2高速缓存是用一种叫做静态随机访问存储器（SRAM）的硬件技术实现的`。比较新的、处理能力更强大的系统甚至有三级高速缓存：L1、L2和L3。系统可以获得一个很大的存储器，同时访问速度也很快，原因是利用了高速缓存的局部性原理，即程序具有访问局部区域里的数据和代码的趋势。`通过让高速缓存里存放可能经常访问的数据，大部分的内存操作都能在快速的高速缓存中完成`。
　　意识到高速缓存存储器存在的应用程序员能够利用高速缓存将程序的性能提高一个数量级。

　　　　　　　　　　　　　　　　<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/02%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/03.png" width=55% height=55%>

　　　　　　　　　　　　　　　　　　　　　图3：一个存储器层次结构的示例

　　存储器层次结构的主要思想是上一层的存储器作为低一层存储器的高速缓存，因此，`寄存器文件就是L1的高速缓存，L1是L2的高速缓存，L2是L3的高速缓存，L3是主存的高速缓存，而主存又是磁盘的高速缓存`。正如可以运用不同的高速缓存的知识来提高程序性能一样，程序员同样可以利用对整个存储器层次结构的理解来提高程序性能。

### 操作系统管理硬件

　　操作系统有两个基本功能：（1）防止硬件被失控的应用程序滥用；（2）向应用程序提供简单一致的机制来控制复杂而又通常大不同的低级硬件设备。操作系统通过几个基本的抽象概念（进程、虚拟内存和文件）来实现这两个功能。其中，文件是对I/O设备的抽象表示，虚拟内存是对主存和磁盘I/O设备的抽象表示，进程则是对处理器、主存和I/O设备的抽象表示。

#### 进程

　　进程是操作系统对一个正在运行的程序的一种抽象，在一个系统上可以同时运行多个进程，而每个进程都好像在独占地使用硬件。其实，操作系统会保持跟踪进程运行所需的所有状态信息。这种状态，也就是上下文，包括许多信息，比如PC和寄存器文件的当前值，以及主存的内容。`在任何一个时刻，单处理器系统都只能执行一个进程的代码`，当操作系统决定要把控制权从当前进程转移到某个新进程时，就会进行上下文切换，即保存当前进程的上下文，恢复新进程的上下文，然后将控制权传递到新进程。

#### 线程

　　尽管通常我们认为一个进程只有单一的控制流，但是在现代系统中，一个进程实际上可以由多个称为线程的执行单元组成，每个线程都运行在进程的上下文中，并共享同样的代码和全局数据。由于网络服务器中对并行处理的需求，线程成为越来越重要的编程模型，因为多线程之间比多进程之间更容易共享数据，也因为线程一般来说都比进程更高效。

#### 虚拟内存

　　`虚拟内存是一个抽象概念，它为每个进程提供了一个假象，即每个进程都在独占地使用主存`。每个进程看到的内存都是一致的，称为虚拟地址空间。在Linux中，地址空间最上面的区域是保留给操作系统中的代码和数据的，这对所有进程来说都是一样。地址空间的底部区域存放用户进程定义的代码和数据。每个进程看到的虚拟地址空间由大量准确定义的区构成，每个区都有专门的功能：
　　**程序代码和数据：**对所有进程来说，代码是从同一固定地址开始，紧接着的是和C全局变量相对应的数据位置。代码和数据区是直接按照可执行目标文件的内容初始化的。
　　**堆：**代码和数据区后紧随着的是运行时堆。代码和数据区在进程一开始运行时就被指定了大小，与此不同，`当调用像malloc和free这样的C标准库函数时，堆可以在运行时动态地扩展和收缩`。
　　**共享库：**大约在地址空间的中间部分是一块用来存放像C标准库和数学库这样的共享库的代码和数据的区
　　**栈：**位于用户虚拟地址空间顶部的是用户栈，编译器用它来实现函数调用。和堆一样，用户栈在程序执行期间可以动态地扩展和收缩。特别地，`每次我们调用一个函数时，栈就会增长；从一个函数返回时，栈就会收缩`。
　　**内核虚拟内存：**地址空间顶部的区域是为内核保留的。不允许应用程序读写这个区域的内容或直接调用内核代码定义的函数。相反，它们必须调用内核来执行这些操作。

　　　　　　　　　　　　　　　　<img src="https://hexo-blog-1258021165.cos.ap-guangzhou.myqcloud.com/02%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/04.png" width=45% height=45%>

　　　　　　　　　　　　　　　　　　　　　图4：进程的虚拟地址空间

　　虚拟内存的运作需要硬件和操作系统软件之间紧密复杂的交互，包括对处理器生成的每个地址的硬件翻译。`基本思想是把一个进程虚拟内存的内容存储在磁盘上，然后用主存作为磁盘的高速缓存`。

#### 文件

　　文件就是字节序列，仅此而已。每个I/O设备，包括磁盘、键盘、显示器、甚至网络，都可以看成是文件。系统中的所有输入输出都是通过使用一小组称为Unix I/O的系统函数调用读写文件来实现的。

#### Amdalhl定律

　　该定律的主要思想是，当我们对系统的某个部分加速时，其对系统整体性能的影响取决于该部分的重要性和加速程度。其得出的主要观点就是，`如果想要显著加速整个系统，就必须提升全系统中相当大的部分的速度，如果只是提升系统的一小部分的速度，就算该部分的速度已经达到了极致的地步，其对整个系统的提升也不会很大`。